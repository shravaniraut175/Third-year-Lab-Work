{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f7aa17",
   "metadata": {},
   "source": [
    "Identify the Peas Description And Task Environment for a Given Real World AI Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2f50d",
   "metadata": {},
   "source": [
    "üå± What is PEAS?\n",
    "\n",
    "PEAS stands for Performance measure, Environment, Actuators, and Sensors.\n",
    "It‚Äôs a framework used to describe any AI agent‚Äôs task environment ‚Äî i.e., what the agent does, how it interacts with the world, and how its success is measured.\n",
    "\n",
    "üß† Structure of PEAS Description:\n",
    "Element\tMeaning\tExample Description\n",
    "P (Performance Measure)\tCriteria to judge success or failure\tAccuracy, profit, time taken, safety, etc.\n",
    "E (Environment)\tThe world in which the agent operates\tRoad, market, web, factory, hospital, etc.\n",
    "A (Actuators)\tWhat the agent can do / its actions\tMove, speak, recommend, brake, etc.\n",
    "S (Sensors)\tHow the agent perceives the environment\tCameras, microphones, input data, etc.\n",
    "\n",
    "\n",
    "üåç Example 1: Self-Driving Car\n",
    "\n",
    "Component\tDescription\n",
    "\n",
    "Performance Measure\tSafety, reaching destination, obeying traffic rules, comfort, fuel efficiency\n",
    "\n",
    "Environment\tRoads, traffic, pedestrians, weather conditions, signals\n",
    "\n",
    "Actuators\tSteering wheel, accelerator, brakes, indicators\n",
    "\n",
    "Sensors\tCameras, LIDAR, radar, GPS, speed sensors\n",
    "\n",
    "---\n",
    "\n",
    "üí¨ Example 2: Chatbot for University Website (similar to your project)\n",
    "\n",
    "Component\tDescription\n",
    "\n",
    "Performance Measure\tAccuracy of responses, user satisfaction, response speed\n",
    "\n",
    "Environment\tUniversity website, database of FAQs, student queries\n",
    "\n",
    "Actuators\tDisplaying text responses on chat interface\n",
    "\n",
    "Sensors\tUser text input, click events, database responses\n",
    "\n",
    "---\n",
    "\n",
    "üè¶ Example 3: Automated Loan Approval System\n",
    "\n",
    "Component\tDescription\n",
    "\n",
    "Performance Measure\tCorrect approval/rejection rate, profit, low default rate\n",
    "\n",
    "Environment\tBank database, applicant data, financial records\n",
    "\n",
    "Actuators\tApprove or reject applications, send notifications\n",
    "\n",
    "Sensors\tApplicant details, credit score, income information\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "üè† Example 4: Smart Home Thermostat\n",
    "\n",
    "Component\tDescription\n",
    "\n",
    "Performance Measure\tMaintaining comfortable temperature, energy efficiency\n",
    "\n",
    "Environment\tHome environment, weather conditions\n",
    "\n",
    "Actuators\tHeater, air conditioner, fan\n",
    "\n",
    "Sensors\tTemperature sensor, humidity sensor, time of day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdce33",
   "metadata": {},
   "source": [
    "1. Smart Home Assistant\n",
    "\n",
    "Problem: Automate and control household devices to enhance convenience, security, and energy efficiency.\n",
    "\n",
    "PEAS:\n",
    "\n",
    "Performance: Accuracy of command recognition, responsiveness, reliability, energy savings, user satisfaction.\n",
    "\n",
    "Environment: Home with smart devices, humans, network infrastructure.\n",
    "\n",
    "Actuators: Device commands, voice feedback, app notifications.\n",
    "\n",
    "Sensors: Microphones, cameras, motion/temperature sensors, network data.\n",
    "\n",
    "Task Environment: Partially observable, single agent, sequential, dynamic, mixed discrete/continuous, stochastic, mostly known.\n",
    "\n",
    "2. Robot Assembler\n",
    "\n",
    "Problem: Automate product assembly efficiently and safely.\n",
    "\n",
    "PEAS:\n",
    "\n",
    "Performance: Speed, accuracy, error rates, safety, adaptability.\n",
    "\n",
    "Environment: Factory floor, parts, tools, machines, humans.\n",
    "\n",
    "Actuators: Robotic arms, grippers, tools.\n",
    "\n",
    "Sensors: Cameras, force sensors, proximity sensors.\n",
    "\n",
    "Task Environment: Fully observable, single/multi-agent, sequential, dynamic, mostly discrete with some continuous, mostly deterministic, mostly known.\n",
    "\n",
    "3. Washing Machine\n",
    "\n",
    "Problem: Wash clothes efficiently while protecting fabrics and optimizing resources.\n",
    "\n",
    "PEAS:\n",
    "\n",
    "Performance: Cleaning effectiveness, energy/water efficiency, wash duration, fabric care.\n",
    "\n",
    "Environment: Laundry room with clothes of various types.\n",
    "\n",
    "Actuators: Water valves, drum motors, dispensers, heaters.\n",
    "\n",
    "Sensors: Water level, temperature, vibration.\n",
    "\n",
    "Task Environment: Fully observable, single agent, episodic, static, mostly discrete with continuous monitoring, mostly deterministic, known.\n",
    "\n",
    "4. Shopping Website\n",
    "\n",
    "Problem: Provide a user-friendly platform for browsing, recommendations, and secure purchases.\n",
    "\n",
    "PEAS:\n",
    "\n",
    "Performance: User engagement, conversion rates, recommendation quality, transaction security, page speed.\n",
    "\n",
    "Environment: Internet users, product catalog, payment & delivery systems.\n",
    "\n",
    "Actuators: Web content updates, recommendations, transaction processing.\n",
    "\n",
    "Sensors: Clicks, searches, browsing history, purchases.\n",
    "\n",
    "Task Environment: Partially observable, multi-agent, sequential, dynamic, mostly discrete with some continuous, stochastic, mostly unknown.\n",
    "\n",
    "5. Image Analysis System\n",
    "\n",
    "Problem: Detect, classify, and interpret visual information for applications like medical diagnosis or autonomous navigation.\n",
    "\n",
    "PEAS:\n",
    "\n",
    "Performance: Detection/classification accuracy, speed, robustness, low error rates.\n",
    "\n",
    "Environment: Images/videos with varying lighting, noise, occlusions.\n",
    "\n",
    "Actuators: Labels, alerts, control commands.\n",
    "\n",
    "Sensors: Cameras or digital image sources.\n",
    "\n",
    "Task Environment: Partially observable, single agent, episodic (batch) or sequential (video), static (images) or dynamic (video), continuous, stochastic, mostly known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f51d38",
   "metadata": {},
   "source": [
    "2. Identify suitable Agent Architecture and type for the problem\n",
    "\n",
    "Imagine a company uses drones to deliver packages in a city. Each drone is equipped with sensors to detect obstacles, GPS for navigation, cameras for visual input and an onboard AI system to decide the best route, avoid collisions and adjust to weather conditions. It can recharge itself when low on battery and notify the control center if it faces a failure. Identify the type of agent used in the above scenario. Draw a suitable agent component diagram and comment on the agent type and its suitability.\n",
    "\n",
    "\n",
    ". Agent Type Analysis\n",
    "\n",
    "Feature\tAgent Type for Drone Delivery\n",
    "\n",
    "- Simple Reflex Agent\t‚ùå Not suitable; reacts only to current sensor data, cannot plan routes or handle dynamic city conditions.\n",
    "\n",
    "- Model-Based Reflex Agent\t‚ö†Ô∏è Partially suitable; maintains internal state (e.g., battery, position) but still lacks goal planning and utility optimization.\n",
    "\n",
    "- Goal-Based Agent\t‚úÖ Suitable; the drone has a clear goal‚Äîdeliver packages. It can plan routes and avoid obstacles to achieve this goal.\n",
    "\n",
    "- Utility-Based Agent\t‚úÖ Highly suitable; the drone can evaluate different routes and trade-offs (battery life, time, weather) to choose the optimal path.\n",
    "\n",
    "- Learning Agent\t‚ö†Ô∏è Optional but beneficial; the drone can improve routing efficiency over time using experience.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The drone system is primarily a Goal-Based and Utility-Based agent, with potential learning capabilities for adaptation. This combination allows it to plan, optimize, and improve over time in a dynamic environment.\n",
    "\n",
    "\n",
    "2. Agent Architecture (Component Diagram)\n",
    "\n",
    "A simplified drone agent architecture can be represented as follows:\n",
    "\n",
    "               +------------------------+\n",
    "               |      Sensors           |\n",
    "               | (GPS, Camera, Lidar,  |\n",
    "               |  Weather, Battery)    |\n",
    "               +-----------+------------+\n",
    "                           |\n",
    "                           v\n",
    "               +------------------------+\n",
    "               |  Perception Module     |\n",
    "               |  (Process sensor data,|\n",
    "               |   update world model) |\n",
    "               +-----------+------------+\n",
    "                           |\n",
    "                           v\n",
    "               +------------------------+\n",
    "               |  Internal World Model  |\n",
    "               |  (State: position,    |\n",
    "               |  battery, environment)|\n",
    "               +-----------+------------+\n",
    "                           |\n",
    "                           v\n",
    "               +------------------------+\n",
    "               |  Decision-Making       |\n",
    "               |  (Goal-based planner,  |\n",
    "               |   Utility evaluator)   |\n",
    "               +-----------+------------+\n",
    "                           |\n",
    "                           v\n",
    "               +------------------------+\n",
    "               |  Action Module         |\n",
    "               |  (Move, Avoid, Recharge|\n",
    "               |   Notify Control)      |\n",
    "               +------------------------+\n",
    "\n",
    "\n",
    "Components Explained:\n",
    "\n",
    "Sensors: Detect obstacles, position, weather, battery status.\n",
    "\n",
    "Perception Module: Converts raw sensor data into meaningful information and updates the internal model.\n",
    "\n",
    "Internal World Model: Maintains memory/state of environment (city layout, battery, package status).\n",
    "\n",
    "Decision-Making Module: Plans routes and chooses actions based on goal achievement and utility.\n",
    "\n",
    "Action Module: Executes chosen actions‚Äînavigation, collision avoidance, recharging, notifications.\n",
    "\n",
    "3. Commentary on Agent Type & Suitability\n",
    "\n",
    "Goal-Based: The drone explicitly pursues the goal of delivering packages efficiently.\n",
    "\n",
    "Utility-Based: It evaluates multiple paths and trade-offs (battery life, time, risk of collisions, weather conditions) to pick the best one.\n",
    "\n",
    "Learning (optional): Over time, the drone can improve route selection and obstacle handling using historical data.\n",
    "\n",
    "Suitability:\n",
    "\n",
    "Handles dynamic, partially observable environments.\n",
    "\n",
    "Makes autonomous, real-time decisions.\n",
    "\n",
    "Optimizes resource use (battery, time).\n",
    "\n",
    "Can adapt and improve over time if learning is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228cdf7",
   "metadata": {},
   "source": [
    "3. Implementation of Breadth first search for problem solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d91197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from A to F : ['A', 'C', 'F']\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs(graph, start, goal):\n",
    "    # Queue stores paths instead of single nodes\n",
    "    queue = deque([[start]])\n",
    "    visited = set()\n",
    "\n",
    "    while queue:\n",
    "        path = queue.popleft()      # Get the first path from queue\n",
    "        node = path[-1]             # Get the last node from path\n",
    "\n",
    "        if node == goal:\n",
    "            return path             # Return the path if goal is found\n",
    "\n",
    "        elif node not in visited:\n",
    "            for neighbour in graph.get(node, []):\n",
    "                new_path = list(path)\n",
    "                new_path.append(neighbour)\n",
    "                queue.append(new_path)\n",
    "            \n",
    "            visited.add(node)\n",
    "\n",
    "    return None  # If no path found\n",
    "\n",
    "# Example graph (Adjacency List)\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['D', 'E'],\n",
    "    'C': ['F'],\n",
    "    'D': [],\n",
    "    'E': ['F'],\n",
    "    'F': []\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "start = 'A'\n",
    "goal = 'F'\n",
    "path = bfs(graph, start, goal)\n",
    "print(\"Path from\", start, \"to\", goal, \":\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba44ed",
   "metadata": {},
   "source": [
    "4. Implementation of Bidirectional search for problem solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7680164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75583c6c",
   "metadata": {},
   "source": [
    "5. Implement Hill Climbing Search for problem solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a4fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at: F\n",
      "\n",
      "Reached goal (local maximum): F\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def hill_climbing(problem, heuristic):\n",
    "    current = random.choice(list(problem.keys()))  # Start from a random node\n",
    "    print(f\"Starting at: {current}\")\n",
    "\n",
    "    while True:\n",
    "        neighbors = problem[current]\n",
    "        if not neighbors:\n",
    "            break\n",
    "\n",
    "        # Evaluate neighbors using the heuristic\n",
    "        neighbor = max(neighbors, key=lambda n: heuristic[n])\n",
    "\n",
    "        # If the neighbor is better, move there\n",
    "        if heuristic[neighbor] > heuristic[current]:\n",
    "            print(f\"Moving from {current} ‚Üí {neighbor}\")\n",
    "            current = neighbor\n",
    "        else:\n",
    "            # Stop if no better neighbor exists\n",
    "            print(f\"No better neighbors found. Stopped at: {current}\")\n",
    "            break\n",
    "\n",
    "    return current\n",
    "\n",
    "# Example graph (each node connects to some neighbors)\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['D', 'E'],\n",
    "    'C': ['F'],\n",
    "    'D': [],\n",
    "    'E': ['F'],\n",
    "    'F': []\n",
    "}\n",
    "\n",
    "# Example heuristic values (higher = better)\n",
    "heuristic = {\n",
    "    'A': 1,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 6,\n",
    "    'F': 8\n",
    "}\n",
    "\n",
    "# Run Hill Climbing\n",
    "result = hill_climbing(graph, heuristic)\n",
    "print(\"\\nReached goal (local maximum):\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a6130",
   "metadata": {},
   "source": [
    "6. Implementation of adversarial search using min-max  algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49aecc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value for the maximizer is: 12\n"
     ]
    }
   ],
   "source": [
    "def minimax(depth, node_index, is_maximizing, values, max_depth):\n",
    "    # Base case: when we reach a leaf node\n",
    "    if depth == max_depth:\n",
    "        return values[node_index]\n",
    "\n",
    "    if is_maximizing:\n",
    "        best = float('-inf')\n",
    "\n",
    "        # Recur for left and right children\n",
    "        best = max(best, minimax(depth + 1, node_index * 2, False, values, max_depth))\n",
    "        best = max(best, minimax(depth + 1, node_index * 2 + 1, False, values, max_depth))\n",
    "        return best\n",
    "    else:\n",
    "        best = float('inf')\n",
    "\n",
    "        # Recur for left and right children\n",
    "        best = min(best, minimax(depth + 1, node_index * 2, True, values, max_depth))\n",
    "        best = min(best, minimax(depth + 1, node_index * 2 + 1, True, values, max_depth))\n",
    "        return best\n",
    "\n",
    "\n",
    "# Example leaf node values (for a small game tree)\n",
    "values = [3, 5, 2, 9, 12, 5, 23, 23]\n",
    "\n",
    "# Height of the tree (log‚ÇÇ of number of leaves)\n",
    "import math\n",
    "max_depth = math.log2(len(values))\n",
    "\n",
    "# Run minimax from root (depth=0, node_index=0, maximizing player)\n",
    "optimal_value = minimax(0, 0, True, values, int(max_depth))\n",
    "\n",
    "print(\"The optimal value for the maximizer is:\", optimal_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed22a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for Maximizer is: 2\n"
     ]
    }
   ],
   "source": [
    "def minimax(depth, isMax):\n",
    "    # Example leaf node values\n",
    "    scores = [3, 5, 2, 9]\n",
    "\n",
    "    # Base condition: return the leaf value\n",
    "    if depth == 2:\n",
    "        return scores[depth]\n",
    "\n",
    "    if isMax:\n",
    "        return max(minimax(depth + 1, False), minimax(depth + 1, False))\n",
    "    else:\n",
    "        return min(minimax(depth + 1, True), minimax(depth + 1, True))\n",
    "\n",
    "print(\"Best value for Maximizer is:\", minimax(0, True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80024d2b",
   "metadata": {},
   "source": [
    "7. Implement knowledge base in Prolog for solving Murder Mystery \n",
    "- Husband and Alice was not together on the night of murder. \n",
    "- The killer and victim were on the beach. \n",
    "- On the night of murder, one male and one female was in the bar. \n",
    "- The victim was twin and the counterpart was innocent. \n",
    "- The killer was younger than the victim. One child was alone at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e96c87",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3896972694.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    location(alice, beach).\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "% Facts: People and their locations\n",
    "location(alice, beach).\n",
    "location(bob, bar).\n",
    "location(charlie, beach).\n",
    "location(diana, beach).\n",
    "location(eve, home).\n",
    "\n",
    "% Ages\n",
    "age(alice, 30).\n",
    "age(charlie, 25).\n",
    "age(diana, 30).\n",
    "\n",
    "% Twins (innocent)\n",
    "twin(alice, diana).\n",
    "twin(diana, alice).\n",
    "\n",
    "% Rule: Killer is on beach, not twin, and younger than victim\n",
    "killer(Killer, Victim) :-\n",
    "    location(Killer, beach),\n",
    "    location(Victim, beach),\n",
    "    \\+ twin(Killer, Victim),\n",
    "    age(Killer, AgeK),\n",
    "    age(Victim, AgeV),\n",
    "    AgeK < AgeV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc1af2",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "Query => ?- killer(K, V)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83232f",
   "metadata": {},
   "source": [
    "8. Implement family tree using prolog programming with different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cacfa",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "% Facts: gender\n",
    "male(john).\n",
    "male(michael).\n",
    "male(david).\n",
    "male(robert).\n",
    "\n",
    "female(susan).\n",
    "female(linda).\n",
    "female(emily).\n",
    "female(kate).\n",
    "\n",
    "% Facts: parent relationships\n",
    "parent(john, michael).\n",
    "parent(john, linda).\n",
    "parent(susan, michael).\n",
    "parent(susan, linda).\n",
    "\n",
    "parent(michael, david).\n",
    "parent(michael, emily).\n",
    "parent(linda, robert).\n",
    "parent(linda, kate).\n",
    "\n",
    "% Rules\n",
    "father(X, Y) :- male(X), parent(X, Y).       % X is father of Y\n",
    "mother(X, Y) :- female(X), parent(X, Y).     % X is mother of Y\n",
    "grandparent(X, Y) :- parent(X, Z), parent(Z, Y). % X is grandparent of Y\n",
    "sibling(X, Y) :- parent(P, X), parent(P, Y), X \\= Y. % X and Y are siblings\n",
    "cousin(X, Y) :- parent(P1, X), parent(P2, Y), sibling(P1, P2). % X and Y are cousins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "851e72ba",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1215165461.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Example Queries\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Example Queries\n",
    "\n",
    "Who is Michael‚Äôs father?\n",
    "\n",
    "?- father(F, michael).\n",
    "\n",
    "\n",
    "Who are Linda‚Äôs children?\n",
    "\n",
    "?- parent(linda, C).\n",
    "\n",
    "\n",
    "Who are David‚Äôs grandparents?\n",
    "\n",
    "?- grandparent(G, david).\n",
    "\n",
    "\n",
    "Are Michael and Linda siblings?\n",
    "\n",
    "?- sibling(michael, linda).\n",
    "\n",
    "\n",
    "Who are David‚Äôs cousins?\n",
    "\n",
    "?- cousin(david, C).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf583d05",
   "metadata": {},
   "source": [
    "9. Implementation for Bayes Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48836d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior probability P(King|Face): 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_King = 4 / 52\n",
    "P_Face_given_King = 1\n",
    "P_Face = 12 / 52\n",
    "\n",
    "# Bayes Theorem\n",
    "P_King_given_Face = (P_Face_given_King * P_King) / P_Face\n",
    "\n",
    "print(\"Posterior probability P(King|Face):\", P_King_given_Face)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
